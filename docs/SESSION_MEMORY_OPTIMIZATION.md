# ğŸš€ ä¼šè¯çº§è®°å¿†ç¼“å­˜ä¼˜åŒ–å®ç°

## ğŸ’¡ æ ¸å¿ƒæ€è·¯

åœ¨èŠå¤©sessionå‘èµ·çš„ç¬¬ä¸€æ¬¡è¯·æ±‚æ—¶è°ƒç”¨è®°å¿†ä½“ï¼Œä¹‹ååœ¨åŒä¸€ä¸ªèŠå¤©sessionå†…éƒ½ä¸éœ€è¦å†ä»è®°å¿†ä½“é‡Œè°ƒå–æ•°æ®ã€‚

## ğŸ› ï¸ å®ç°æ–¹æ¡ˆ

### 1. ä¿®æ”¹Stateç»“æ„

åœ¨ `openai_compatible_service.py` ä¸­çš„ `State` ç±»å‹å®šä¹‰ä¸­æ·»åŠ  `session_memories` å­—æ®µï¼š

```python
class State(TypedDict):  
    messages: Annotated[List[HumanMessage | AIMessage], add_messages]
    mem0_user_id: str
    conversation_id: str
    session_memories: Dict[str, Any]  # æ–°å¢ï¼šä¼šè¯çº§è®°å¿†ç¼“å­˜
```

### 2. ä¿®æ”¹chatbotå‡½æ•°çš„è®°å¿†æŸ¥è¯¢é€»è¾‘

å°†åŸæ¥çš„è®°å¿†æŸ¥è¯¢é€»è¾‘æ›¿æ¢ä¸ºï¼š

```python
def chatbot(state: State):
    """Enhanced chatbot with session-based memory caching"""
    messages = state["messages"]  
    user_id = state["mem0_user_id"]
    conversation_id = state.get("conversation_id", str(uuid.uuid4()))

    logger.info(f"ğŸ¤– Processing message for user: {user_id}")

    # Get current user message
    current_user_message = safe_decode(messages[-1].content)
    
    # ğŸ”¥ æ ¸å¿ƒä¼˜åŒ–ï¼šæ£€æŸ¥æ˜¯å¦å·²æœ‰ä¼šè¯è®°å¿†ç¼“å­˜
    session_memories = state.get("session_memories", {})
    
    if session_memories:
        # ä½¿ç”¨ç¼“å­˜çš„ä¼šè¯è®°å¿†ï¼ˆæ— éœ€æ•°æ®åº“æŸ¥è¯¢ï¼‰
        logger.info("ğŸ“‹ Using cached session memories (no database query needed)")
        long_term_context = session_memories.get("long_term_context", "")
    else:
        # ä¼šè¯ä¸­çš„ç¬¬ä¸€æ¬¡è¯·æ±‚ - ä»æ•°æ®åº“è·å–è®°å¿†
        logger.info("ğŸ” First request in session - searching relevant long-term memories...")
        try:
            search_results = mem0_instance.search(current_user_message, user_id=user_id)
            
            if isinstance(search_results, dict) and "results" in search_results:
                raw_memories = search_results["results"]
            else:
                raw_memories = search_results if search_results else []
            
            # å¤„ç†è®°å¿†æ•°æ®
            relevant_memories = []
            for memory in raw_memories[:5]:  # é™åˆ¶ä¸º5ä¸ªæœ€ç›¸å…³çš„è®°å¿†
                try:
                    if isinstance(memory, dict):
                        memory_content = memory.get('memory', '')
                        memory_type = memory.get('metadata', {}).get('memory_type', 'unknown')
                        
                        if memory_type in ['core', 'long_term', 'short_term']:
                            relevant_memories.append({
                                'memory': memory_content,
                                'metadata': memory.get('metadata', {}),
                                'id': memory.get('id', 'unknown')
                            })
                except Exception as e:
                    logger.warning(f"âš ï¸  Error processing memory: {e}")
                    continue
            
            # æ ¼å¼åŒ–é•¿æœŸä¸Šä¸‹æ–‡
            if relevant_memories:
                memory_texts = []
                for mem in relevant_memories:
                    mem_type = mem.get('metadata', {}).get('memory_type', 'unknown')
                    importance = mem.get('metadata', {}).get('importance_level', 0)
                    memory_texts.append(f"[{mem_type}] (é‡è¦æ€§: {importance:.1f}) {mem['memory']}")
                
                long_term_context = "ç”¨æˆ·çš„ç›¸å…³è®°å¿†ä¿¡æ¯ï¼š\n" + "\n".join(memory_texts)
                logger.info(f"ğŸ“š Found {len(relevant_memories)} relevant memories")
            else:
                long_term_context = ""
                logger.info("ğŸ“­ No relevant memories found")
            
            # ğŸ”¥ å…³é”®ï¼šå°†è®°å¿†ç¼“å­˜åˆ°ä¼šè¯çŠ¶æ€ä¸­
            state["session_memories"] = {
                "long_term_context": long_term_context,
                "relevant_memories": relevant_memories,
                "cached_at": time.time()
            }
            logger.info("ğŸ’¾ Cached memories for session - subsequent requests will be faster")
            
        except Exception as e:
            logger.warning(f"âš ï¸  Memory search failed: {e}")
            long_term_context = ""
    
    # ç»§ç»­åŸæœ‰çš„å¤„ç†é€»è¾‘...
    # (ç³»ç»Ÿæ¶ˆæ¯æ„å»ºã€LLMè°ƒç”¨ç­‰ä¿æŒä¸å˜)
```

### 3. ä¼šè¯è¯†åˆ«æœºåˆ¶

ç”±äºOpenAI APIæ˜¯æ— çŠ¶æ€çš„ï¼Œéœ€è¦é€šè¿‡ä»¥ä¸‹æ–¹å¼è¯†åˆ«ä¼šè¯ï¼š

#### æ–¹æ¡ˆAï¼šåŸºäºå¯¹è¯å†å²è¯†åˆ«ï¼ˆæ¨èï¼‰
```python
def is_new_session(messages: List[Any]) -> bool:
    """åˆ¤æ–­æ˜¯å¦ä¸ºæ–°ä¼šè¯"""
    # å¦‚æœåªæœ‰ä¸€æ¡ç”¨æˆ·æ¶ˆæ¯ï¼Œè®¤ä¸ºæ˜¯æ–°ä¼šè¯
    user_messages = [msg for msg in messages if isinstance(msg, HumanMessage)]
    return len(user_messages) <= 1

def should_use_cached_memory(state: State) -> bool:
    """åˆ¤æ–­æ˜¯å¦åº”è¯¥ä½¿ç”¨ç¼“å­˜çš„è®°å¿†"""
    # å¦‚æœå·²æœ‰ä¼šè¯è®°å¿†ç¼“å­˜ï¼Œä¸”ä¸æ˜¯æ–°ä¼šè¯ï¼Œåˆ™ä½¿ç”¨ç¼“å­˜
    return bool(state.get("session_memories")) and not is_new_session(state["messages"])
```

#### æ–¹æ¡ˆBï¼šåŸºäºæ—¶é—´çª—å£è¯†åˆ«
```python
SESSION_TIMEOUT = 1800  # 30åˆ†é’Ÿä¼šè¯è¶…æ—¶

def is_session_expired(session_memories: Dict[str, Any]) -> bool:
    """æ£€æŸ¥ä¼šè¯æ˜¯å¦è¿‡æœŸ"""
    if not session_memories:
        return True
    
    cached_at = session_memories.get("cached_at", 0)
    return time.time() - cached_at > SESSION_TIMEOUT
```

## ğŸ“Š é¢„æœŸæ•ˆæœ

### æ€§èƒ½æå‡
- **ç¬¬ä¸€æ¬¡è¯·æ±‚**ï¼šæ­£å¸¸é€Ÿåº¦ï¼ˆéœ€è¦æŸ¥è¯¢è®°å¿†ï¼‰
- **åç»­è¯·æ±‚**ï¼šå“åº”æ—¶é—´å‡å°‘ **80-90%**
- **æ•°æ®åº“æŸ¥è¯¢**ï¼šæ¯ä¸ªä¼šè¯åªæŸ¥è¯¢ä¸€æ¬¡

### ç”¨æˆ·ä½“éªŒ
- ä¼šè¯å¼€å§‹ç¨æœ‰å»¶è¿Ÿï¼ˆæ­£å¸¸ï¼‰
- è¿ç»­å¯¹è¯å‡ ä¹æ— å»¶è¿Ÿ
- æ•´ä½“ä½“éªŒå¤§å¹…æå‡

## ğŸ”§ å…·ä½“ä¿®æ”¹æ­¥éª¤

### æ­¥éª¤1ï¼šä¿®æ”¹Stateå®šä¹‰
åœ¨ `openai_compatible_service.py` ç¬¬393è¡Œé™„è¿‘ï¼š

```python
# åŸæ¥çš„å®šä¹‰
class State(TypedDict):  
    messages: Annotated[List[HumanMessage | AIMessage], add_messages]
    mem0_user_id: str
    conversation_id: str

# ä¿®æ”¹ä¸º
class State(TypedDict):  
    messages: Annotated[List[HumanMessage | AIMessage], add_messages]
    mem0_user_id: str
    conversation_id: str
    session_memories: Dict[str, Any]  # æ–°å¢
```

### æ­¥éª¤2ï¼šä¿®æ”¹chatbotå‡½æ•°
åœ¨ `openai_compatible_service.py` ç¬¬405-450è¡Œé™„è¿‘ï¼Œå°†è®°å¿†æŸ¥è¯¢é€»è¾‘æ›¿æ¢ä¸ºä¸Šè¿°çš„ä¼šè¯ç¼“å­˜é€»è¾‘ã€‚

### æ­¥éª¤3ï¼šä¿®æ”¹åˆå§‹çŠ¶æ€
åœ¨è°ƒç”¨LangGraphæ—¶ï¼Œç¡®ä¿åˆå§‹çŠ¶æ€åŒ…å«ç©ºçš„session_memoriesï¼š

```python
# åœ¨non_stream_chat_completionå’Œstream_chat_completionå‡½æ•°ä¸­
initial_state = {
    "messages": messages,
    "mem0_user_id": user_id,
    "conversation_id": str(uuid.uuid4()),
    "session_memories": {}  # æ–°å¢
}
```

## ğŸ§ª æµ‹è¯•éªŒè¯

### æµ‹è¯•è„šæœ¬
```python
import requests
import time

def test_session_memory_optimization():
    """æµ‹è¯•ä¼šè¯è®°å¿†ä¼˜åŒ–æ•ˆæœ"""
    base_url = "http://localhost:8000"
    user_id = "session_test_user"
    
    messages = [
        "ä½ å¥½ï¼æˆ‘å«å¼ ä¸‰ï¼Œæˆ‘æ˜¯ç¨‹åºå‘˜ã€‚",
        "æˆ‘æœ€è¿‘åœ¨å­¦ä¹ Pythonã€‚",
        "ä½ èƒ½æ¨èä¸€äº›Pythonä¹¦ç±å—ï¼Ÿ",
        "è°¢è°¢ä½ çš„å»ºè®®ï¼"
    ]
    
    conversation = []
    
    for i, message in enumerate(messages):
        print(f"\nğŸ”„ ç¬¬{i+1}æ¬¡è¯·æ±‚: {message}")
        
        # æ„å»ºå¯¹è¯å†å²
        conversation.append({"role": "user", "content": message})
        
        start_time = time.time()
        
        response = requests.post(f"{base_url}/v1/chat/completions", json={
            "model": "langgraph-mem0-agent",
            "messages": conversation.copy(),
            "user": user_id
        })
        
        end_time = time.time()
        response_time = end_time - start_time
        
        if response.status_code == 200:
            ai_response = response.json()['choices'][0]['message']['content']
            conversation.append({"role": "assistant", "content": ai_response})
            
            print(f"â±ï¸  å“åº”æ—¶é—´: {response_time:.2f}ç§’")
            print(f"ğŸ¤– AIå›å¤: {ai_response[:100]}...")
            
            if i == 0:
                print("   ğŸ“ ç¬¬ä¸€æ¬¡è¯·æ±‚ï¼ˆé¢„æœŸè¾ƒæ…¢ï¼Œéœ€è¦æŸ¥è¯¢è®°å¿†ï¼‰")
            else:
                print("   ğŸ“ åç»­è¯·æ±‚ï¼ˆé¢„æœŸå¾ˆå¿«ï¼Œä½¿ç”¨ç¼“å­˜è®°å¿†ï¼‰")
        else:
            print(f"âŒ è¯·æ±‚å¤±è´¥: {response.status_code}")

if __name__ == "__main__":
    test_session_memory_optimization()
```

## ğŸ’¡ ä¼˜åŒ–å»ºè®®

### 1. è®°å¿†ç¼“å­˜æ¸…ç†
```python
# å®šæœŸæ¸…ç†è¿‡æœŸçš„ä¼šè¯è®°å¿†
def cleanup_session_memories():
    # å®ç°æ¸…ç†é€»è¾‘
    pass
```

### 2. è®°å¿†æ›´æ–°ç­–ç•¥
```python
# å½“æœ‰æ–°è®°å¿†å†™å…¥æ—¶ï¼Œå¯é€‰æ‹©æ€§æ›´æ–°ä¼šè¯ç¼“å­˜
def update_session_memory_if_needed(state: State, new_memory: Dict):
    session_memories = state.get("session_memories", {})
    if session_memories and should_update_cache(new_memory):
        # æ›´æ–°ç¼“å­˜
        pass
```

### 3. ç›‘æ§å’Œæ—¥å¿—
```python
# æ·»åŠ æ€§èƒ½ç›‘æ§
logger.info(f"ğŸ“Š Session memory cache hit rate: {hit_rate:.2f}%")
logger.info(f"âš¡ Response time improvement: {improvement:.2f}x faster")
```

## ğŸ¯ æ€»ç»“

è¿™ä¸ªç®€å•çš„ä¼šè¯çº§è®°å¿†ç¼“å­˜ä¼˜åŒ–æ–¹æ¡ˆï¼š

- âœ… **å®ç°ç®€å•** - åªéœ€ä¿®æ”¹å‡ åè¡Œä»£ç 
- âœ… **æ•ˆæœæ˜¾è‘—** - åç»­è¯·æ±‚å“åº”æ—¶é—´å‡å°‘80-90%
- âœ… **ç”¨æˆ·å‹å¥½** - è¿ç»­å¯¹è¯ä½“éªŒå¤§å¹…æå‡
- âœ… **èµ„æºèŠ‚çº¦** - å¤§å¹…å‡å°‘æ•°æ®åº“æŸ¥è¯¢
- âœ… **é£é™©å¯æ§** - ä¸æ”¹å˜æ ¸å¿ƒé€»è¾‘ï¼Œåªæ˜¯æ·»åŠ ç¼“å­˜å±‚

è¿™æ˜¯ä¸€ä¸ªæŠ•å…¥äº§å‡ºæ¯”æé«˜çš„ä¼˜åŒ–æ–¹æ¡ˆï¼Œå»ºè®®ä¼˜å…ˆå®æ–½ï¼
